reserved characters are $ and .

size limit is 16MB/doc

mongoimport --db pcat -c test2 < test.js

http://docs.mongodb.org/manual/use-cases/

http://docs.mongodb.org/manual/reference/commands/

Aggregation Framework
- group by
- map reduce
- aggregation pipeline

Sharding is partitioning of data
Replication is redundant/multiple copies of same data - HA/Failover/DR-Distaster Recovery
Each shard have different data
Replication is async. Single Primary/Master at a time. It master,slave replication
Mongo Drivers are replica set aware

best practices
- dont use IP
- dont use names from /etc/hosts
- use dns pick appropriate TTL

// insert data
// find data
// restart primary 
// check data

HTTP UI 
default port 27017 + 1000 = 28017 port
http admin ui port = 28017
http://localhost:28017/
http://www.mongodb.org/display/DOCS/Http+Interface
mongod --rest

optime = 64bit = 32 bit ctime + 32 bit ordinal value

db.oplog.rs.find().limit(4)

Capped Collection - delete not allowed, preserve insertion order

db.printReplicationInfo()

http://localhost:28017/test/system.indexes/
http://localhost:28017/test/foo/

arbiter - to break the ties, do not have any data, is a voter

config options
arbiterOnly:true
primary - 0(never be primary) - greater the value greater the chance to be primary
hidden:true (not in use)
slaveDelay:1*3600 //1 hour seconds(forcing the slave member to lag behind 8 hrs)
votes:n (as a best practice dont use votes)
tags: (data center awareness stuff)

cfg = rs.conf()
rs.reconfg(cfg)

change the hostname/dnsname for the instances if recycling them is required

majority->committed

principles
1. write is truly committed upon app @ a majority of the set
2. we can get ack of this.

//Write concern. write and get acknowledgement
db.foo.insert({x:1})
db.getLastError({w:'majority', wtimeout:8000})
w is how many server we like to get ack from
w:1
w:'all'
w:3
GLE - get last error

MODES				| USE CASE
1. no call to GLE   | page view counter (no user input)
2. w:1  			| not super critical. caching scenario
3. w:'majorty' 		| most things important
4. w:3 (all)   		| flow control thing
5. w:tag

call GLE every N
GLE every N + sharding => reliability issue

* use write concern
* use w majority
* tune iff slow
* call GLE when job ends

Batch Inserts

In ReplicaSet the number of member need to be odd number. To create some majority

Recommended Example Configs
- 1 DC - datacenter
3 members ***
2 + 1 arbiter *
2 with manual failover *
5 members (??)
2 large + 1 small (?)
for scaleout dont use replication

2 data centers need to have 1 arbiter in other location than the 2

limits
per set <= 12 members
<= 7 voters

raad preference "slave ok"
primary - default
 primary preffered - secondary is possible
 secondary - secondary is possible
 secondary preferred  secondary is possible 
 nearest - secondary is possible
 * when in doubt use primary preference
 * when remote use nearest
 * use sec for certain reporting workloads
 * even read loads consider nearest
 
 fieldnames are not in the index

 Hint not always works

 At any given point in time a single document lives at only 1 shard
 However, in replica set single document is replicated accross all the nodes of replica set
 Replica Set for High Availability, Data Safety
 Sharding for scaleout

 In mongo Sharding is range based partitioning


 nameL  nameH	shard
 jane	joe		S2
 joe	kyle	S0
 kyle	matt	S1

 ['jane','joe'] -> S2 - range is reffered as Chunk ~ 100 MB each

 Data Distribution has liveliness and has no locking
 	Operations
 	1. Split - inexpensive
 	2. Migrate - expensive
 balancer is component of software decides when todo migrations
3 config servers in production
1 config server for development
so 1 or 3 config server is the only possibility

best practices
- run mongos on the standard mongodb tcp port 27017
- do not run shard server mongods nor config servers on that port

by default collections are not sharded

scatter/gather - is sending query to all shards. Queries like ensureIndex or find without shardKey will go to all shards

Shard Key Selection
- good cardinality/granularity
- shard key is common in queries for the collection
- consider compound shard keys
- is the key monotonically increasting? (BSON ObjectIDs are monotonically increasing) - avoid them

Sharding Tips
- only shard big collections
- pick shard key carefully
- consider presplitting on a bulk load
- be awere of monotonically increasing shard key values on inserts
- adding shards is fairly easy but is not instantaneous
- always connect to mongos except for dba work
- put mongos on default port
- user logical config server names
- if changing config servers read the docs!

Security Modes
1. Trusted Environemnt - lock down @ network lyer relevant tcp ports
2. MongoDB Authentications
-- auth - securing client acccess (authentication + authorization for clients)
-- keyfile - intro cluster (authentication for nodes) - works with both mongod and mongos

in auth and keyfile traffic is not encrypted
- data is unencrypted
- but credentials are not in plain text

docs.mongodb.org/manual/administration/ssl

scons --ssl

type of users (clients)
admin users
 admin commands
 created in admin database
 can access all dbs
regular users
 access specific db
 read/write or readonly
 can create/remove indexes

Backup and Restore
- mongodump
- filesystem snapshot - lvm, san, amazon ebs

- backup from secondary
 - shutdown, copy files , restart

mongodump --oplog
mongorestore --oplogReplay

Backing up Sharded Servers
1. turn off balancer. sh.stopBalancer()
2. backup config db
mongodump --db config
3. backup each shard's ReplSet
4. sh.startBalancer()

dbname.ns
dbname.0
dbname.1
.
.
.
journal/
j.-0
j.-1
.
.
.
typically 3 file in journal directory

geospatial indexes
- 2d only


Additional Features
- Capped Collections :circular queues, cannot delete or grow, pre allocated max size, recently inserted order
- TTL Collections: auto ages out of old docs, creating special index

GridFS for storing binary files. Large blob storage. utility: mongofiles

Hardware/Software Tips
- fast cpu clock is better as compared to more cores
- 64 bit
- RAM is good
- disable NUMA
- SSDs are good
 - reserve some free space ~ 20%
- filesystem cache is mongods memory usage
- check readahead setting! (small value for random read writes) - Linux command bbckdev --report

www.mongodb.org/DOCS/Production+Notes

Additional Resources
- docs - mongoddb.org
- driver docs
- bug database / feature
- jira.mongodb.org
- support forms - mongodb-user in google - free
- irc freenode.net/#mongodb
blog.mongodb.org
twitter @mongodb
Meetup Groups
- MMS  - cloud based version is free





